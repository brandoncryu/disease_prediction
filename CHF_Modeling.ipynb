{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklean\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('./data/CHF_final_test.csv.gz', compression='gzip')\n",
    "hadm_features = final.loc[:, '(\\'min\\', 50861)' : '(\\'above_max\\', 51491)']\n",
    "hadm_target = final.loc[:, 'CHF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-afc15aa422ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhadm_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhadm_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhadm_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_selection' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(hadm_features, hadm_target, test_size=.2, stratify=hadm_target, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6880dd2c96a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Over and under sample the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_res_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearMiss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Over and under sample the train set\n",
    "sm = SMOTE()\n",
    "X_res_over, y_res_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "nm = NearMiss()\n",
    "X_res_under, y_res_under = nm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target counts\n",
    "hadm_target[hadm_target==0].count()\n",
    "hadm_target[hadm_target==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model):\n",
    "    '''\n",
    "    Function to report on the metrics of a GridSearch model.\n",
    "    Input: GridSearchCV model\n",
    "    Prints: CV score, best parameters, accuracy, precision, recall, F1, confusion matrix and ROCAUC\n",
    "    '''\n",
    "    \n",
    "#     cross validation scores\n",
    "    print(\"Cross Validation\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Best parameter: \", model.best_params_)\n",
    "    print(\"Best CV score:  %.4f\" % model.best_score_)\n",
    "\n",
    "#     confusion matrix & related scores\n",
    "    pred = model.best_estimator_.predict(X_test)\n",
    "    print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(\"Classification Report:\", end='')\n",
    "    print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n",
    "    \n",
    "# #     ROCAUC\n",
    "#     if model.estimator.__class__== sklearn.linear_model._logistic.LogisticRegression:\n",
    "#         from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#         y_pred = model.best_estimator_.decision_function(X_test)\n",
    "#         fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "#         auc = auc(fpr, tpr)\n",
    "\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"Area Under Curve: {auc:.2f}%\")\n",
    "\n",
    "#         svc_disp = plot_roc_curve(model, X_test, y_test)\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print('not logistic')\n",
    "    svc_disp = plot_roc_curve(model, X_test, y_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(grid_search_RF_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params ={'C':range(1, 1000, 200)}\n",
    "logReg = LogisticRegression(penalty = 'l1', max_iter = 2000, class_weight = \"balanced\", solver = 'liblinear')\n",
    "\n",
    "grid_log = GridSearchCV(estimator = logReg, param_grid = params, cv = 3)\n",
    "grid_log.fit(X_train, y_train)\n",
    "grid_log.best_score_\n",
    "\n",
    "results(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, grid_log.best_estimator_.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params ={'C':range(1, 1000, 200)}\n",
    "logReg = LogisticRegression(penalty = 'l1', max_iter = 2000, class_weight = \"balanced\", solver = 'liblinear')\n",
    "\n",
    "grid_log_over = GridSearchCV(estimator = logReg, param_grid = params, cv = 3)\n",
    "grid_log_over.fit(X_res_over, y_res_over)\n",
    "grid_log_over.best_score_\n",
    "\n",
    "results(grid_log_Over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under Sampling using Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params ={'C':range(1, 1000, 100)}\n",
    "logReg = LogisticRegression(penalty = 'l1', max_iter = 2000, class_weight = \"balanced\", solver = 'liblinear')\n",
    "\n",
    "grid_log_under = GridSearchCV(estimator = logReg, param_grid = params, cv = 3)\n",
    "grid_log_under.fit(X_res_under, y_res_under)\n",
    "grid_log_under.best_score_\n",
    "\n",
    "results(grid_log_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31,10),\n",
    "            'max_depth': range(10,110,20)\n",
    "            }\n",
    "\n",
    "grid_rf = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "results(grid_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31,10),\n",
    "            'max_depth': range(10,110,20)\n",
    "            }\n",
    "\n",
    "grid_rf_over = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_rf_over.fit(X_res_over, y_res_over)\n",
    "\n",
    "results(grid_rf_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under Sampling using Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31,10),\n",
    "            'max_depth': range(10,110,20)\n",
    "            }\n",
    "\n",
    "grid_rf_under = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_rf_under.fit(X_res_under, y_res_under)\n",
    "\n",
    "results(grid_rf_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive approach using 1. n_estimators 2. max_depth, min_samples\n",
    "# perhaps use randomsearch instead of gridsearch\n",
    "# look at area under curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "            }\n",
    "\n",
    "grid_gb = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "results(grid_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling using SMOTEÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "            }\n",
    "\n",
    "grid_gb_over = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_gb_over.fit(X_res_over, y_res_over)\n",
    "\n",
    "results(grid_gb_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under Sampling using Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "            }\n",
    "\n",
    "grid_gb_under = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_gb_under.fit(X_res, y_res)\n",
    "\n",
    "results(grid_gb_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Imputed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_final = pd.read_csv('./CHF_KNN_final_test.csv.gz', compression='gzip')\n",
    "hadm_features = KNN_final.loc[:, '(\\'min\\', 50861)' : '(\\'above_max\\', 51491)']\n",
    "hadm_target = KNN_final.loc[:, 'CHF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(hadm_features, hadm_target, test_size=.2, stratify=hadm_target, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31),\n",
    "            'max_depth': range(10,110,10)\n",
    "            }\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### undersampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31),\n",
    "            'max_depth': range(10,110,10)\n",
    "            }\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling using Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss()\n",
    "X_res, y_res = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid={'criterion': ['entropy','gini'],\n",
    "            'n_estimators': range(1,31),\n",
    "            'max_depth': range(10,110,10)\n",
    "            }\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "            }\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling using Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss()\n",
    "X_res, y_res = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "param_grid={'n_estimators':range(20,81,20),\n",
    "            'max_depth':range(5,16,4),\n",
    "            'min_samples_split':range(20,100,30),\n",
    "            'max_features':range(7,20,5),\n",
    "            }\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_grid, cv=3)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Cross Validation\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Best parameter: \", grid_search.best_params_)\n",
    "print(\"Best CV score:  %.4f\" % grid_search.best_score_)\n",
    "\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try running with just creatinine items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
